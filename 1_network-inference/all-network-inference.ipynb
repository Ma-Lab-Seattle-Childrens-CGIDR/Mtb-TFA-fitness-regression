{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4f4906-02ef-43df-b14b-d04940da6fcd",
   "metadata": {},
   "source": [
    "# Mtb Network Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c03e939-1c6a-4d02-b153-fb5c9ba61a92",
   "metadata": {},
   "source": [
    "In order to generate inferred networks from transcriptional data, you must have access to a command line with docker installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2e543-ba57-4122-9e2e-4ca55ca5f456",
   "metadata": {},
   "source": [
    "## Obtaining docker images\n",
    "\n",
    "### Building a single image\n",
    "\n",
    "All docker images used here can be built from the dockerfiles supplied. To do this, simply run a command like:\n",
    "\n",
    "```\n",
    "docker build -t clr 1_network-inference/docker/clr\n",
    "```\n",
    "\n",
    "See `docker build --help` for more details on using this command.\n",
    "\n",
    "### Building all images\n",
    "\n",
    "All images can be built with the following series of commands:\n",
    "\n",
    "```\n",
    "for dir in 1_network-inference/docker/*; do docker build -t $(basename $dir) $dir; done\n",
    "```\n",
    "\n",
    "### Pulling images from Dockerhub\n",
    "\n",
    "Alternatively, most images can also be pulled from Dockerhub from the `ethanbustadscri` account. To do this, run a command like:\n",
    "\n",
    "```\n",
    "docker pull ethanbustadscri/clr:0.1 && docker tag ethanbustadscri/clr:0.1 clr\n",
    "```\n",
    "\n",
    "This will fetch the pre-built image and give it a name as expected below. See `docker pull --help` and `docker tag --help` for more details on these commands.\n",
    "\n",
    "The ARACNe image is notably missing from Dockerhub, as its license does not allow redistribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa05572d-f4a3-4a11-8095-5858c3df8239",
   "metadata": {},
   "source": [
    "## Running docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4084343-02df-4b66-af8c-b1af62b25f2f",
   "metadata": {},
   "source": [
    "Once the inference method docker images are obtained, they can each be run to infer a regulatory network based on the transcriptional data aggregated previously.\n",
    "\n",
    "Inference must be executed once for each dataset. Hyperparameters can be adjusted as desired -- here are supplied the hyperparameters used in our investigation.\n",
    "\n",
    "### GSE59086 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3bc5ca-e12d-43ea-b3b9-a4ce4e51e152",
   "metadata": {},
   "source": [
    "#### ARACNe\n",
    "\n",
    "```\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    aracne \\\n",
    "        /root/mount/0_transcriptome-aggregation/out/GSE59086_pysnail.tsv \\\n",
    "        /root/mount/1_network-inference/in/mtb_tfs_214_Mycobrowser.txt \\\n",
    "        /root/mount/1_network-inference/out/aracne_GSE59086.txt \\\n",
    "        y \\\n",
    "        1E-6 \\\n",
    "        6 \\\n",
    "        100\n",
    "```\n",
    "\n",
    "Currently, this docker image does not have help text available. The positional parameters it accepts are:\n",
    "- `expression_file`: tab-delimited text file containing expression information\n",
    "- `regulators_file`: newline-delimited text file containing the list of transcription factors to use for inference\n",
    "- `out_file`: the location where results will be written, as a tab-delimited text file\n",
    "- `transpose`: whether or not to transpose the `expression_file` before passing to ARACNe proper; ARACNe expects files in the form of genes × samples, but a file in the form of samples × genes can be passed if `transpose` is `y` or `yes` (all other arguments will be interpreted as `no`; optional, defaults to `n`)\n",
    "- `p_value`: the p-value cutoff used by ARACNe, see https://github.com/califano-lab/ARACNe-AP#parameters (optional, defaults to 1 × 10<sup>-8</sup>)\n",
    "- `threads`: the number of CPU cores to use for processing, see https://github.com/califano-lab/ARACNe-AP#parameters (optional, defaults to 4)\n",
    "- `bootstraps`: the number of random bootstrap networks to generate before consolidation, see https://github.com/califano-lab/ARACNe-AP#parameters (optional, defaults to 10, which is likely insufficient)\n",
    "- `memory_gbs`: the number of gigabytes of memory to supply to the ARACNe process (optional, defaults to 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950dba8-cf39-44ff-b08b-3413c9ee14f0",
   "metadata": {},
   "source": [
    "#### CLR\n",
    "\n",
    "```\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    clr \\\n",
    "        /root/mount/0_transcriptome-aggregation/out/GSE59086_pysnail.tsv \\\n",
    "        /root/mount/1_network-inference/in/mtb_tfs_214_Mycobrowser.txt \\\n",
    "        /root/mount/1_network-inference/out/clr_GSE59086.txt \\\n",
    "        --rows=samples\n",
    "```\n",
    "\n",
    "More usage details can be found using\n",
    "\n",
    "```\n",
    "docker run -it --rm clr --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bae626-c7ca-42fd-a291-b6409aaaf622",
   "metadata": {},
   "source": [
    "#### GENIE3\n",
    "\n",
    "```\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    genie3 \\\n",
    "        /root/mount/0_transcriptome-aggregation/out/GSE59086_pysnail.tsv \\\n",
    "        /root/mount/1_network-inference/in/mtb_tfs_214_Mycobrowser.txt \\\n",
    "        /root/mount/1_network-inference/out/genie3_GSE59086.txt \\\n",
    "        --rows=samples\n",
    "```\n",
    "\n",
    "More usage details can be found using\n",
    "\n",
    "```\n",
    "docker run -it --rm genie3 --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5203a-c514-4d0f-a0f9-526dd8a4171b",
   "metadata": {},
   "source": [
    "#### Elastic net\n",
    "\n",
    "```\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    elasticnet \\\n",
    "        /root/mount/0_transcriptome-aggregation/out/GSE59086_pysnail.tsv \\\n",
    "        /root/mount/1_network-inference/in/mtb_tfs_214_Mycobrowser.txt \\\n",
    "        /root/mount/1_network-inference/out/elasticnet_GSE59086.txt \\\n",
    "        --n_cores=6 \\\n",
    "        -vv\n",
    "```\n",
    "\n",
    "More usage details can be found using\n",
    "\n",
    "```\n",
    "docker run -it --rm elasticnet --help\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6507cd-c1bc-4378-9f16-0f04b0ee0d94",
   "metadata": {},
   "source": [
    "#### cMonkey2\n",
    "\n",
    "```\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    cmonkey2 \\\n",
    "        --organism mtu \\\n",
    "        --out /root/mount/cmonkey2/mtu \\\n",
    "        --num_cores 6 \\\n",
    "        --rsat_base_url http://networks.systemsbiology.net/rsat \\\n",
    "        --rsat_organism Mycobacterium_tuberculosis_H37Rv \\\n",
    "        --debug \\\n",
    "        /root/mount/0_transcriptome-aggregation/out/GSE59086_pysnail.tsv\n",
    "\n",
    "# now transform the cMonkey2 output into the desired output\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    --entrypoint /root/cmonkey_process.sh \\\n",
    "    cmonkey2 \\\n",
    "        /root/mount/cmonkey2/mtu/cmonkey_run.db \\\n",
    "        /root/mount/1_network-inference/in/mtb_tfs_214_Mycobrowser.txt \\\n",
    "        /root/mount/1_network-inference/out/cmonkey2_GSE59086.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7aa0a-8bc0-4850-ab27-8ea0b4b56153",
   "metadata": {},
   "source": [
    "#### iModulon\n",
    "\n",
    "iModulon is by far the most long-running inference method used in this investigation. Here, processing is split up into multiple jobs that can be run in parallel, in order to complete the operation in a more reasonable amount of time. With the `--tolerance` and `--iterations` parameters used here, inference still takes days to complete.\n",
    "\n",
    "```\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    imodulon \\\n",
    "        --expression_file /root/mount/mtb_expression_master-20240215.tsv \\\n",
    "        --tolerance 1e-7 \\\n",
    "        --out_dir /root/mount/imodulon3 \\\n",
    "        --iterations 100 \\\n",
    "        --dim_end 280 \\\n",
    "        --dim_step 20 \\\n",
    "        --finalize False\n",
    "\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    imodulon \\\n",
    "        --expression_file /root/mount/mtb_expression_master-20240215.tsv \\\n",
    "        --tolerance 1e-7 \\\n",
    "        --out_dir /root/mount/imodulon3 \\\n",
    "        --iterations 100 \\\n",
    "        --dim_begin 280 \\\n",
    "        --dim_end 400 \\\n",
    "        --dim_step 20 \\\n",
    "        --finalize False\n",
    "\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    imodulon \\\n",
    "        --expression_file /root/mount/mtb_expression_master-20240215.tsv \\\n",
    "        --tolerance 1e-7 \\\n",
    "        --out_dir /root/mount/imodulon3 \\\n",
    "        --iterations 100 \\\n",
    "        --dim_begin 400 \\\n",
    "        --dim_end 420 \\\n",
    "        --dim_step 20 \\\n",
    "        --finalize False\n",
    "\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    imodulon \\\n",
    "        --expression_file /root/mount/mtb_expression_master-20240215.tsv \\\n",
    "        --tolerance 1e-7 \\\n",
    "        --out_dir /root/mount/imodulon3 \\\n",
    "        --iterations 100 \\\n",
    "        --dim_begin 420 \\\n",
    "        --dim_end 440 \\\n",
    "        --dim_step 20 \\\n",
    "        --finalize False\n",
    "\n",
    "# now consolidate all results together\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    imodulon \\\n",
    "        --expression_file /root/mount/mtb_expression_master-20240215.tsv \\\n",
    "        --tolerance 1e-7 \\\n",
    "        --out_dir /root/mount/imodulon3 \\\n",
    "        --finalize only\n",
    "\n",
    "# now transform the iModulon output into the desired output\n",
    "docker run -it --rm \\\n",
    "    --volume ..:/root/mount \\\n",
    "    --entrypoint /root/imodulon_process.sh \\\n",
    "    imodulon \\\n",
    "        /root/mount/imodulon/M.csv \\\n",
    "        /root/mount/1_network-inference/in/mtb_tfs_214_Mycobrowser.txt \\\n",
    "        /root/mount/1_network-inference/out/imodulon_GSE59086.txt\n",
    "```\n",
    "\n",
    "More usage details can be found using\n",
    "\n",
    "```\n",
    "docker run -it --rm imodulon --help\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```\n",
    "docker run -it --rm --entrypoint /root/imodulon_process.sh imodulon --help\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
